version: '3.8'

services:
  spark_app:
    container_name: spark_app
    build:
      context: spark/
      dockerfile: Dockerfile
    env_file:
      - ./.env
    depends_on:
      - postgres_dwh
      - twitter_handle
      - airflow-webserver
    command: "driver local:///opt/application/process_twitter_stream.py"

  postgres_dwh:
    container_name: postgres_dwh
    image: postgres:13-alpine
    environment:
      - POSTGRES_USER=wordle_pulse
      - POSTGRES_PASSWORD=wordle_pulse
      - POSTGRES_DB=wordle_pulse
    ports:
      - "5444:5432"
    volumes:
      # - ./postgres-data:/var/lib/postgresql/data
      - ./postgres/sql/create_tables.sql:/docker-entrypoint-initdb.d/init.sql

  twitter_handle:
    container_name: twitter_handle
    build:
      context: twitter_handle/
      dockerfile: Dockerfile
    env_file:
      - ./.env

  postgres:
    image: postgres:13-alpine
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    logging:
      options:
        max-size: 10m
        max-file: "3"
    ports:
      - "5432:5432"

  airflow-webserver:
    image: puckel/docker-airflow:1.10.9
    restart: always
    depends_on:
      - postgres
      - postgres_dwh
    environment:
      - LOAD_EX=n
      - EXECUTOR=Local
      - FERNET_KEY=0ynpgvcurgWPWcWfBB-D-hcukL_zydAMnnmTe3XKjgE=
      - AIRFLOW_CONN_POSTGRES_DEFAULT=postgres://airflow:airflow@postgres:5432/airflow
    logging:
      options:
        max-size: 10m
        max-file: "3"
    volumes:
      - ./airflow/dags:/usr/local/airflow/dags
    ports:
      - "8080:8080"
    command: webserver
    healthcheck:
      test: ["CMD-SHELL", "[ -f /usr/local/airflow/airflow-webserver.pid ]"]
      interval: 30s
      timeout: 30s
      retries: 3

  dashboard:
    build:
      context: dashboard/
      dockerfile: Dockerfile
    env_file:
      - ./.env
    environment:
        - PORT=8000
    ports:
        - 8000:8000
    depends_on:
      - postgres_dwh
